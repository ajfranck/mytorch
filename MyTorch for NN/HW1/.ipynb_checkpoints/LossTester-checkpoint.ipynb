{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853f2b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from mytorch import nn as mynn\n",
    "from mytorch.optim import SGD\n",
    "from torch import nn\n",
    "import torch\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b79796c",
   "metadata": {},
   "source": [
    "# MSE Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaca201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up synthetic data\n",
    "N = 10\n",
    "num_inputs = 7\n",
    "num_outputs = 3\n",
    "\n",
    "# numpy/our versions\n",
    "W = np.random.rand(num_inputs, num_outputs)\n",
    "b = np.random.rand(num_outputs, 1)\n",
    "X = np.random.randn(N, num_inputs)\n",
    "Y = X @ W + np.outer(np.ones(N), b) + 0.5 * np.random.randn(N, num_outputs)\n",
    "\n",
    "# converted torch versions\n",
    "Xt = torch.tensor(X).float()\n",
    "Wt = torch.tensor(W).float()\n",
    "bt = torch.tensor(b).float()\n",
    "Yt = torch.tensor(Y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eacc512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model and fix weights to true values\n",
    "my_net = mynn.Linear(num_inputs, num_outputs)\n",
    "my_net.W = W\n",
    "my_net.b = b\n",
    "\n",
    "# initialize torch model, loss, optimizer\n",
    "net = nn.Linear(num_inputs, num_outputs)\n",
    "net.weight = nn.Parameter(Wt.T)\n",
    "net.bias = nn.Parameter(bt[:, 0])\n",
    "torch_out = net(Xt)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3af0862",
   "metadata": {},
   "source": [
    "## Test `forward()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6252b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch loss function\n",
    "torch_mse_fn = nn.MSELoss()\n",
    "torch_mse = torch_mse_fn(torch_out, Yt)\n",
    "\n",
    "# mytorch loss function\n",
    "my_mse_fn = mynn.MSELoss()\n",
    "my_mse = my_mse_fn.forward(torch_out.detach().numpy(), Y)\n",
    "\n",
    "print('Torch MSE:', torch_mse.data)\n",
    "print('My MSE:', my_mse, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83257ff1",
   "metadata": {},
   "source": [
    "## Test `backward()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f79d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "optimizer.zero_grad()\n",
    "torch_out = net(Xt)\n",
    "torch_mse = torch_mse_fn(torch_out, Yt)\n",
    "torch_mse.backward(retain_graph=True)\n",
    "torch_dLdW = net.weight.grad.data\n",
    "torch_dLdb = net.bias.grad.data\n",
    "\n",
    "dLdZ = my_mse_fn.backward()\n",
    "my_net.forward(X)\n",
    "my_net.backward(dLdZ)\n",
    "my_dLdW = my_net.dLdW\n",
    "my_dLdb = my_net.dLdb\n",
    "\n",
    "print('MyTorch dLdW:\\n', my_dLdW, '\\n')\n",
    "print('PyTorch dLdW:\\n', torch_dLdW.T, '\\n')\n",
    "print('MyTorch dLdb:\\n', my_dLdb, '\\n')\n",
    "print('PyTorch dLdb:\\n', torch_dLdb, '\\n')\n",
    "\n",
    "print('Difference in dLdW:', np.linalg.norm(my_dLdW.T - torch_dLdW.data.numpy()))\n",
    "print('Difference in dLdb:', np.linalg.norm(my_dLdb.flatten() - torch_dLdb.data.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200ac53c",
   "metadata": {},
   "source": [
    "# CE Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f98a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up synthetic data\n",
    "N = 10\n",
    "num_inputs = 7\n",
    "num_outputs = 3\n",
    "\n",
    "# numpy/our versions\n",
    "W = np.random.rand(num_inputs, num_outputs)\n",
    "b = np.random.rand(num_outputs, 1)\n",
    "# generate random one-hot matrix\n",
    "x = np.eye(num_outputs)\n",
    "x[np.random.choice(x.shape[0], size=N)]\n",
    "Y = np.eye(num_outputs)[np.random.choice(num_outputs, N)]\n",
    "\n",
    "# converted torch versions\n",
    "Xt = torch.tensor(X).float()\n",
    "Wt = torch.tensor(W).float()\n",
    "bt = torch.tensor(b).float()\n",
    "Yt = torch.tensor(Y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f768330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model and fix weights to true values\n",
    "my_net = mynn.Linear(num_inputs, num_outputs)\n",
    "my_net.W = W\n",
    "my_net.b = b\n",
    "\n",
    "# initialize torch model, loss, optimizer\n",
    "net = nn.Linear(num_inputs, num_outputs)\n",
    "net.weight = nn.Parameter(Wt.T)\n",
    "net.bias = nn.Parameter(bt[:, 0])\n",
    "torch_out = net(Xt)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eec2722",
   "metadata": {},
   "source": [
    "## Test `forward()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11dd9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch loss functions\n",
    "torch_ce_fn = nn.CrossEntropyLoss()\n",
    "torch_ce = torch_ce_fn(torch_out, Yt)\n",
    "\n",
    "# mytorch loss functions\n",
    "my_ce_fn = mynn.CrossEntropyLoss()\n",
    "my_ce = my_ce_fn.forward(torch_out.detach().numpy(), Y)\n",
    "\n",
    "print('Torch CE:', torch_ce.data)\n",
    "print('My CE:', my_ce, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5e3d3c",
   "metadata": {},
   "source": [
    "## Test `backward()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881a59c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "torch_out = net(Xt)\n",
    "torch_ce = torch_ce_fn(torch_out, Yt)\n",
    "torch_ce.backward(retain_graph=True)\n",
    "torch_dLdW = net.weight.grad.data\n",
    "torch_dLdb = net.bias.grad.data\n",
    "\n",
    "dLdZ = my_ce_fn.backward()\n",
    "my_net.forward(X)\n",
    "my_net.backward(dLdZ)\n",
    "my_dLdW = my_net.dLdW\n",
    "my_dLdb = my_net.dLdb\n",
    "\n",
    "print('MyTorch dLdW:\\n', my_dLdW, '\\n')\n",
    "print('PyTorch dLdW:\\n', torch_dLdW.T, '\\n')\n",
    "print('MyTorch dLdb:\\n', my_dLdb, '\\n')\n",
    "print('PyTorch dLdb:\\n', torch_dLdb, '\\n')\n",
    "\n",
    "print('Difference in dLdW:', np.linalg.norm(my_dLdW.T - torch_dLdW.data.numpy()))\n",
    "print('Difference in dLdb:', np.linalg.norm(my_dLdb.flatten() - torch_dLdb.data.numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
