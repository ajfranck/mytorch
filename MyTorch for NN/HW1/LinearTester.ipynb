{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "656dcd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch\n",
    "from d2l import torch as d2l\n",
    "\n",
    "import mytorch\n",
    "from mytorch import nn as mynn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d6bd7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data for testing\n",
    "data = np.load('testerData.npz')\n",
    "W, b, X, Y, dLdZ = [data[fname] for fname in data.files]\n",
    "\n",
    "[N, num_inputs] = X.shape\n",
    "num_outputs = Y.shape[1]\n",
    "\n",
    "# converted torch versions\n",
    "Xt = torch.tensor(X).float()\n",
    "Wt = torch.tensor(W).float()\n",
    "bt = torch.tensor(b).float()\n",
    "Yt = torch.tensor(Y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fbacf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model and fix weights to true values\n",
    "my_net = mynn.Linear(num_inputs, num_outputs)\n",
    "my_net.W = W\n",
    "my_net.b = b.flatten()\n",
    "\n",
    "# initialize torch model, loss, optimizer\n",
    "net = nn.Linear(num_inputs, num_outputs)\n",
    "net.weight = nn.Parameter(Wt.T)\n",
    "net.bias = nn.Parameter(bt[:, 0])\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c82e02",
   "metadata": {},
   "source": [
    "## Compare `forward()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5ebee13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:\n",
      " [[2.45419505 3.85377348 3.86239248 4.09861525 3.42552912]\n",
      " [2.37093331 3.22945671 2.88333967 3.03220271 2.72105395]\n",
      " [1.90472749 2.88840363 2.93526692 3.4361838  3.17490315]\n",
      " [1.45392748 2.79782519 2.16759199 2.56624407 2.53054982]\n",
      " [2.04588663 3.40446758 2.76237953 3.22387254 2.86430505]] \n",
      "\n",
      "MyTorch:\n",
      " [[2.45419505 3.85377348 3.86239248 4.09861525 3.42552912]\n",
      " [2.37093331 3.22945671 2.88333967 3.03220271 2.72105395]\n",
      " [1.90472749 2.88840363 2.93526692 3.4361838  3.17490315]\n",
      " [1.45392748 2.79782519 2.16759199 2.56624407 2.53054982]\n",
      " [2.04588663 3.40446758 2.76237953 3.22387254 2.86430505]] \n",
      "\n",
      "PyTorch:\n",
      " tensor([[2.4542, 3.8538, 3.8624, 4.0986, 3.4255],\n",
      "        [2.3709, 3.2295, 2.8833, 3.0322, 2.7211],\n",
      "        [1.9047, 2.8884, 2.9353, 3.4362, 3.1749],\n",
      "        [1.4539, 2.7978, 2.1676, 2.5662, 2.5305],\n",
      "        [2.0459, 3.4045, 2.7624, 3.2239, 2.8643]]) \n",
      "\n",
      "Difference: 7.96027202151818e-07\n"
     ]
    }
   ],
   "source": [
    "true_out = X @ W + np.outer(np.ones(N), b)\n",
    "my_out = my_net.forward(X)\n",
    "torch_out = net(Xt)\n",
    "\n",
    "print('True:\\n', true_out, '\\n')\n",
    "print('MyTorch:\\n', my_out, '\\n')\n",
    "print('PyTorch:\\n', torch_out.data, '\\n')\n",
    "\n",
    "print('Difference:', np.linalg.norm(my_out - torch_out.data.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a732a2",
   "metadata": {},
   "source": [
    "## Compare `backward` and gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a52e538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyTorch dLdW:\n",
      " [[ 0.12012567  0.00295367  0.04191126 -0.07267667  0.02791693]\n",
      " [ 0.03518954 -0.0200141   0.03406723 -0.02431096  0.02070968]\n",
      " [ 0.14748257 -0.01532951  0.08382155 -0.01930616 -0.0203474 ]\n",
      " [ 0.06681007 -0.03891314  0.08080953  0.01504673  0.00045012]\n",
      " [ 0.11256331 -0.01973837  0.01680606 -0.00138297  0.00995075]\n",
      " [ 0.01978376 -0.02740623  0.02936517  0.03265669 -0.00413681]\n",
      " [ 0.13485436 -0.00176794  0.03313958 -0.00091217 -0.01160413]\n",
      " [ 0.02693809 -0.02455704  0.0399628   0.00525783  0.00168999]\n",
      " [ 0.14058303 -0.02630857  0.0610937  -0.01097525  0.00104313]\n",
      " [ 0.06542919 -0.01061266 -0.00446366  0.03434501 -0.00295966]] \n",
      "\n",
      "PyTorch dLdW:\n",
      " tensor([[ 0.1201,  0.0030,  0.0419, -0.0727,  0.0279],\n",
      "        [ 0.0352, -0.0200,  0.0341, -0.0243,  0.0207],\n",
      "        [ 0.1475, -0.0153,  0.0838, -0.0193, -0.0203],\n",
      "        [ 0.0668, -0.0389,  0.0808,  0.0150,  0.0005],\n",
      "        [ 0.1126, -0.0197,  0.0168, -0.0014,  0.0100],\n",
      "        [ 0.0198, -0.0274,  0.0294,  0.0327, -0.0041],\n",
      "        [ 0.1349, -0.0018,  0.0331, -0.0009, -0.0116],\n",
      "        [ 0.0269, -0.0246,  0.0400,  0.0053,  0.0017],\n",
      "        [ 0.1406, -0.0263,  0.0611, -0.0110,  0.0010],\n",
      "        [ 0.0654, -0.0106, -0.0045,  0.0343, -0.0030]]) \n",
      "\n",
      "MyTorch dLdb:\n",
      " [ 0.17004118 -0.02935796  0.06321571 -0.02123358  0.01974512] \n",
      "\n",
      "PyTorch dLdb:\n",
      " tensor([ 0.1700, -0.0294,  0.0632, -0.0212,  0.0197]) \n",
      "\n",
      "Difference in dLdW: 1.1085912244326638e-07\n",
      "Difference in dLdb: 6.319506077808191e-08\n"
     ]
    }
   ],
   "source": [
    "my_net.backward(dLdZ)\n",
    "my_dLdW = my_net.dLdW\n",
    "my_dLdb = my_net.dLdb\n",
    "\n",
    "optimizer.zero_grad()\n",
    "torch_loss_fn = nn.MSELoss()\n",
    "torch_loss = torch_loss_fn(torch_out, Yt)\n",
    "torch_loss.backward(retain_graph=True)\n",
    "torch_dLdW = net.weight.grad.data\n",
    "torch_dLdb = net.bias.grad.data\n",
    "\n",
    "print('MyTorch dLdW:\\n', my_dLdW, '\\n')\n",
    "print('PyTorch dLdW:\\n', torch_dLdW.T, '\\n')\n",
    "print('MyTorch dLdb:\\n', my_dLdb, '\\n')\n",
    "print('PyTorch dLdb:\\n', torch_dLdb, '\\n')\n",
    "\n",
    "print('Difference in dLdW:', np.linalg.norm(my_dLdW.T - torch_dLdW.data.numpy()))\n",
    "print('Difference in dLdb:', np.linalg.norm(my_dLdb.flatten() - torch_dLdb.data.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d491b5",
   "metadata": {},
   "source": [
    "## Compare a single optimization step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2aba6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyTorch Wk:\n",
      " [[0.00225624 0.65454369 0.22786553 0.20375799 0.41525752]\n",
      " [0.06995093 0.09965917 0.54460619 0.32926168 0.65353759]\n",
      " [0.69258879 0.6152178  0.48305614 0.45607477 0.16900205]\n",
      " [0.05864521 0.35032098 0.24489474 0.8639804  0.83109932]\n",
      " [0.7373715  0.07190249 0.15495887 0.52788239 0.4534458 ]\n",
      " [0.14922424 0.40519783 0.92280482 0.5548514  0.28792973]\n",
      " [0.09215936 0.45045506 0.78606601 0.93621087 0.64919466]\n",
      " [0.28578957 0.23344379 0.51530289 0.79663504 0.54019491]\n",
      " [0.22328781 0.61469977 0.93714608 0.01456096 0.10773379]\n",
      " [0.06160243 0.89891648 0.83156413 0.43773651 0.74866049]] \n",
      "\n",
      "PyTorch Wk:\n",
      " tensor([[0.0023, 0.6545, 0.2279, 0.2038, 0.4153],\n",
      "        [0.0700, 0.0997, 0.5446, 0.3293, 0.6535],\n",
      "        [0.6926, 0.6152, 0.4831, 0.4561, 0.1690],\n",
      "        [0.0586, 0.3503, 0.2449, 0.8640, 0.8311],\n",
      "        [0.7374, 0.0719, 0.1550, 0.5279, 0.4534],\n",
      "        [0.1492, 0.4052, 0.9228, 0.5549, 0.2879],\n",
      "        [0.0922, 0.4505, 0.7861, 0.9362, 0.6492],\n",
      "        [0.2858, 0.2334, 0.5153, 0.7966, 0.5402],\n",
      "        [0.2233, 0.6147, 0.9371, 0.0146, 0.1077],\n",
      "        [0.0616, 0.8989, 0.8316, 0.4377, 0.7487]]) \n",
      "\n",
      "MyTorch bk:\n",
      " [[0.61248868 0.96033306 0.09868591 0.80567634 0.61423769]] \n",
      "\n",
      "PyTorch bk:\n",
      " tensor([0.6125, 0.9603, 0.0987, 0.8057, 0.6142])\n",
      "Difference in Wk: 1.037580056856067e-07\n",
      "Difference in bk: 2.613949504884645e-08\n"
     ]
    }
   ],
   "source": [
    "# my SGD step\n",
    "my_optimizer = mytorch.optim.SGD(my_net, lr=0.1)\n",
    "my_optimizer.step()\n",
    "my_Wk = my_net.W\n",
    "my_bk = my_net.b\n",
    "\n",
    "# torch SGD step\n",
    "optimizer.zero_grad()\n",
    "torch_loss.backward(retain_graph=True)\n",
    "optimizer.step()\n",
    "torch_Wk = net.weight.data\n",
    "torch_bk = net.bias.data\n",
    "\n",
    "print('MyTorch Wk:\\n', my_Wk, '\\n')\n",
    "print('PyTorch Wk:\\n', torch_Wk.T, '\\n')\n",
    "print('MyTorch bk:\\n', my_bk, '\\n')\n",
    "print('PyTorch bk:\\n', torch_bk)\n",
    "\n",
    "print('Difference in Wk:', np.linalg.norm(my_Wk - torch_Wk.data.numpy().T))\n",
    "print('Difference in bk:', np.linalg.norm(my_bk.flatten() - torch_bk.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1f7f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
