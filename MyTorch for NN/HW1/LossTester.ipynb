{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "853f2b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from mytorch import nn as mynn\n",
    "from mytorch.optim import SGD\n",
    "from torch import nn\n",
    "import torch\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b79796c",
   "metadata": {},
   "source": [
    "# MSE Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aaca201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up synthetic data\n",
    "N = 10\n",
    "num_inputs = 7\n",
    "num_outputs = 3\n",
    "\n",
    "# numpy/our versions\n",
    "W = np.random.rand(num_inputs, num_outputs)\n",
    "b = np.random.rand(num_outputs, 1)\n",
    "X = np.random.randn(N, num_inputs)\n",
    "Y = X @ W + np.outer(np.ones(N), b) + 0.5 * np.random.randn(N, num_outputs)\n",
    "\n",
    "# converted torch versions\n",
    "Xt = torch.tensor(X).float()\n",
    "Wt = torch.tensor(W).float()\n",
    "bt = torch.tensor(b).float()\n",
    "Yt = torch.tensor(Y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eacc512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model and fix weights to true values\n",
    "my_net = mynn.Linear(num_inputs, num_outputs)\n",
    "my_net.W = W\n",
    "my_net.b = b\n",
    "\n",
    "# initialize torch model, loss, optimizer\n",
    "net = nn.Linear(num_inputs, num_outputs)\n",
    "net.weight = nn.Parameter(Wt.T)\n",
    "net.bias = nn.Parameter(bt[:, 0])\n",
    "torch_out = net(Xt)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3af0862",
   "metadata": {},
   "source": [
    "## Test `forward()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6252b8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch MSE: tensor(0.2180)\n",
      "My MSE: 0.21803364618155888 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# torch loss function\n",
    "torch_mse_fn = nn.MSELoss()\n",
    "torch_mse = torch_mse_fn(torch_out, Yt)\n",
    "\n",
    "# mytorch loss function\n",
    "my_mse_fn = mynn.MSELoss()\n",
    "my_mse = my_mse_fn.forward(torch_out.detach().numpy(), Y)\n",
    "\n",
    "print('Torch MSE:', torch_mse.data)\n",
    "print('My MSE:', my_mse, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83257ff1",
   "metadata": {},
   "source": [
    "## Test `backward()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95f79d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyTorch dLdW:\n",
      " [[ 0.15629022 -0.01670823 -0.01395194]\n",
      " [ 0.02062998 -0.02817953 -0.14405865]\n",
      " [-0.06217844 -0.01217057  0.05367357]\n",
      " [ 0.09557618  0.01814454 -0.02136826]\n",
      " [ 0.03588844 -0.06888509 -0.01345359]\n",
      " [ 0.0222143  -0.0438693  -0.08048498]\n",
      " [ 0.12853376 -0.09517782  0.00418429]] \n",
      "\n",
      "PyTorch dLdW:\n",
      " tensor([[ 0.1563, -0.0167, -0.0140],\n",
      "        [ 0.0206, -0.0282, -0.1441],\n",
      "        [-0.0622, -0.0122,  0.0537],\n",
      "        [ 0.0956,  0.0181, -0.0214],\n",
      "        [ 0.0359, -0.0689, -0.0135],\n",
      "        [ 0.0222, -0.0439, -0.0805],\n",
      "        [ 0.1285, -0.0952,  0.0042]]) \n",
      "\n",
      "MyTorch dLdb:\n",
      " [-0.03687998  0.13018967 -0.13604935] \n",
      "\n",
      "PyTorch dLdb:\n",
      " tensor([-0.0369,  0.1302, -0.1360]) \n",
      "\n",
      "Difference in dLdW: 7.343191299264743e-08\n",
      "Difference in dLdb: 1.4674534402403805e-08\n"
     ]
    }
   ],
   "source": [
    "# MSE\n",
    "optimizer.zero_grad()\n",
    "torch_out = net(Xt)\n",
    "torch_mse = torch_mse_fn(torch_out, Yt)\n",
    "torch_mse.backward(retain_graph=True)\n",
    "torch_dLdW = net.weight.grad.data\n",
    "torch_dLdb = net.bias.grad.data\n",
    "\n",
    "dLdZ = my_mse_fn.backward()\n",
    "my_net.forward(X)\n",
    "my_net.backward(dLdZ)\n",
    "my_dLdW = my_net.dLdW\n",
    "my_dLdb = my_net.dLdb\n",
    "\n",
    "print('MyTorch dLdW:\\n', my_dLdW, '\\n')\n",
    "print('PyTorch dLdW:\\n', torch_dLdW.T, '\\n')\n",
    "print('MyTorch dLdb:\\n', my_dLdb, '\\n')\n",
    "print('PyTorch dLdb:\\n', torch_dLdb, '\\n')\n",
    "\n",
    "print('Difference in dLdW:', np.linalg.norm(my_dLdW.T - torch_dLdW.data.numpy()))\n",
    "print('Difference in dLdb:', np.linalg.norm(my_dLdb.flatten() - torch_dLdb.data.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200ac53c",
   "metadata": {},
   "source": [
    "# CE Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "057f98a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up synthetic data\n",
    "N = 10\n",
    "num_inputs = 7\n",
    "num_outputs = 3\n",
    "\n",
    "# numpy/our versions\n",
    "W = np.random.rand(num_inputs, num_outputs)\n",
    "b = np.random.rand(num_outputs, 1)\n",
    "# generate random one-hot matrix\n",
    "x = np.eye(num_outputs)\n",
    "x[np.random.choice(x.shape[0], size=N)]\n",
    "Y = np.eye(num_outputs)[np.random.choice(num_outputs, N)]\n",
    "\n",
    "# converted torch versions\n",
    "Xt = torch.tensor(X).float()\n",
    "Wt = torch.tensor(W).float()\n",
    "bt = torch.tensor(b).float()\n",
    "Yt = torch.tensor(Y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f768330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model and fix weights to true values\n",
    "my_net = mynn.Linear(num_inputs, num_outputs)\n",
    "my_net.W = W\n",
    "my_net.b = b\n",
    "\n",
    "# initialize torch model, loss, optimizer\n",
    "net = nn.Linear(num_inputs, num_outputs)\n",
    "net.weight = nn.Parameter(Wt.T)\n",
    "net.bias = nn.Parameter(bt[:, 0])\n",
    "torch_out = net(Xt)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eec2722",
   "metadata": {},
   "source": [
    "## Test `forward()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e11dd9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch CE: tensor(1.6076)\n",
      "My CE: 1.4981077154179694 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# torch loss functions\n",
    "torch_ce_fn = nn.CrossEntropyLoss()\n",
    "torch_ce = torch_ce_fn(torch_out, Yt)\n",
    "\n",
    "# mytorch loss functions\n",
    "my_ce_fn = mynn.CrossEntropyLoss()\n",
    "my_ce = my_ce_fn.forward(torch_out.detach().numpy(), Y)\n",
    "\n",
    "print('Torch CE:', torch_ce.data)\n",
    "print('My CE:', my_ce, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5e3d3c",
   "metadata": {},
   "source": [
    "## Test `backward()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "881a59c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyTorch dLdW:\n",
      " [[-2.42025283 -0.74964799 -4.02664113]\n",
      " [ 1.271734   -2.08355641 -1.50988379]\n",
      " [-3.78258475  0.56260216 -0.22064712]\n",
      " [-0.12173315  0.01676124 -2.289436  ]\n",
      " [ 0.62239384 -0.81948011  0.28667337]\n",
      " [ 2.05611344  0.6249941   1.40096314]\n",
      " [ 0.54078871  0.71594616 -1.41667321]] \n",
      "\n",
      "PyTorch dLdW:\n",
      " tensor([[ 0.1990, -0.1686, -0.0303],\n",
      "        [-0.2816, -0.2838,  0.5654],\n",
      "        [-0.0604,  0.1042, -0.0438],\n",
      "        [ 0.0676,  0.1027, -0.1702],\n",
      "        [ 0.0580, -0.1197,  0.0617],\n",
      "        [-0.0905, -0.0410,  0.1315],\n",
      "        [-0.0730, -0.3267,  0.3996]]) \n",
      "\n",
      "MyTorch dLdb:\n",
      " [-0.68258679 -1.88425163  1.19849675] \n",
      "\n",
      "PyTorch dLdb:\n",
      " tensor([ 0.0650,  0.0972, -0.1622]) \n",
      "\n",
      "Difference in dLdW: 8.002632024295615\n",
      "Difference in dLdb: 2.517237004940137\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "torch_out = net(Xt)\n",
    "torch_ce = torch_ce_fn(torch_out, Yt)\n",
    "torch_ce.backward(retain_graph=True)\n",
    "torch_dLdW = net.weight.grad.data\n",
    "torch_dLdb = net.bias.grad.data\n",
    "\n",
    "dLdZ = my_ce_fn.backward()\n",
    "my_net.forward(X)\n",
    "my_net.backward(dLdZ)\n",
    "my_dLdW = my_net.dLdW\n",
    "my_dLdb = my_net.dLdb\n",
    "\n",
    "print('MyTorch dLdW:\\n', my_dLdW, '\\n')\n",
    "print('PyTorch dLdW:\\n', torch_dLdW.T, '\\n')\n",
    "print('MyTorch dLdb:\\n', my_dLdb, '\\n')\n",
    "print('PyTorch dLdb:\\n', torch_dLdb, '\\n')\n",
    "\n",
    "print('Difference in dLdW:', np.linalg.norm(my_dLdW.T - torch_dLdW.data.numpy()))\n",
    "print('Difference in dLdb:', np.linalg.norm(my_dLdb.flatten() - torch_dLdb.data.numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
